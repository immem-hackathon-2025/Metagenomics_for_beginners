# Whats in my sample?

There are thousands of questions you may ask, where metagenomics could be of interest. One of the most basic ones is perhaps "whats in my sample?" Here, we will outline some strategies for how you can go about that questions, and some of the tools out there which can help you find some answers. We will of course also mention some common pitfalls, and situations where you need to be cautious.

## Before you start analysing: QC check the raw data!

Did the sequencing work as intended? How much data did you get, and whats the quality of it? The quality (and amount) of data you get from your sequencing matters a lot for what you can do with your data in terms of analysis. Sometimes, everything is great, other times you may need to trim your data.

Quality control of sequencing data has been around for as long as there has been sequencing, so there are lots of well established tools to choose from.

If you are working on illumina data, [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) has been around for a long time. The software is easy to run, and you get a nice report in the form of an html-file, which you can open in your browser. There are also examples and explanations to help you understand the plots in the report. If you have a larger number of samples, you can also try [MultiQC](https://github.com/MultiQC/MultiQC); this tool can aggregate a collection of reports (fx generated by FastQC) into a single report, which will show you the broad trends in your data across samples. If you are working on nanopore, there are also tools which can produce nice visual reports, fx [NanoPlot](https://github.com/wdecoster/NanoPlot), or [PycoQC](https://a-slide.github.io/pycoQC/installation/) (though this tool is unfortunately no longer being actively maintained).

Having checked the quality and yield, you need to decide whether trimming is needed. The answer depends  on how you plan to analyse your data (i.e. how you will be using the data). 

## Getting a first overview

Starting out, it can be very helpful to just get a rough overview of your samples. Is it all human DNA? All E.coli? Maybe there is a specific type of organism you are interested, does it look like it might be in there?At this stage, you are really just getting to know your data. Therefore, a simple and fast analysis is a good place to start. A widely used tool which can do that for you is [kraken](https://github.com/DerrickWood/kraken2). 

## De novo assembly (or not)

Doing metagenomics is often about digging into the unknown. We want to discover new things. In that sense, de novo assembly is attractive. 

But, you need to have coverage, quite a lot actually. Furthermore, strain-level diversity can put obstacles in your way.

## Leaning on a database

Can be a very powerful way to gain insights into your data. There are so many databases out there, that it can be quite daunting.

## Making your own database

## So you found a possible suspect (for whats in your sample). But can you trust it?

Depends a lot on the database you are using. Once you have a suspect, there are some things you can do to feel more confident about your result.

- If you used a noisy database, try a more specific one containing your suspect.
- Is there a reference genome out there? Map your reads to it. Percentage identity? Horizontal coverage? Are there other things it could also be (perhaps you wanna do competitive mapping)?
